{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eotvDyyZtoHW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question** 1 : What is Simple Linear Regression (SLR)? Explain its purpose.\n",
        "\n",
        "**Ans**:Simple Linear Regression (SLR)\n",
        "\n",
        "Simple Linear Regression is a statistical technique used to understand and model the relationship between one independent variable (X) and one dependent variable (Y). It assumes that this relationship can be represented using a straight line.\n",
        "\n",
        "Mathematical Equation of SLR\n",
        "\n",
        "The equation of Simple Linear Regression is\n",
        "\n",
        "y = mx + c\n",
        "\n",
        "where\n",
        "\n",
        "y = dependent variable (output)\n",
        "\n",
        "x = independent variable (input)\n",
        "\n",
        "m = slope of the line (rate of change of y with respect to x)\n",
        "\n",
        "c = intercept (value of y when x = 0)\n",
        "\n",
        "Meaning of Slope and Intercept\n",
        "\n",
        "Slope (m)\n",
        "The slope shows how much the dependent variable changes when the independent variable increases by one unit.\n",
        "\n",
        "If m is positive, y increases as x increases.\n",
        "\n",
        "If m is negative, y decreases as x increases.\n",
        "\n",
        "Intercept (c)\n",
        "The intercept is the value of y when x equals zero. It represents the starting point of the line on the y-axis.\n",
        "\n",
        "Purpose of Simple Linear Regression\n",
        "\n",
        "Understand relationships\n",
        "It helps identify whether and how strongly one variable affects another.\n",
        "\n",
        "Prediction\n",
        "It allows us to predict future or unknown values of the dependent variable based on known values of the independent variable.\n",
        "\n",
        "Trend analysis\n",
        "It helps in identifying trends in data using a simple and interpretable model.\n",
        "\n",
        "Decision making\n",
        "Businesses and researchers use it to make data-driven decisions.\n",
        "\n",
        "Proper Example\n",
        "\n",
        "Suppose a company wants to understand how years of experience affect an employee’s salary.\n",
        "\n",
        "Independent variable (X): Years of Experience\n",
        "\n",
        "Dependent variable (Y): Salary (in lakhs)\n",
        "\n",
        "Years of Experience (X)\tSalary (Y)\n",
        "1\t3\n",
        "2\t4\n",
        "3\t5\n",
        "4\t6\n",
        "5\t7\n",
        "\n",
        "After applying Simple Linear Regression, we may get the equation\n",
        "\n",
        "y = 1x + 2\n",
        "\n",
        "This means\n",
        "\n",
        "For every 1 year increase in experience, salary increases by 1 lakh.\n",
        "\n",
        "When experience is 0 years, the estimated salary is 2 lakhs.\n",
        "\n",
        "Prediction Using the Model\n",
        "\n",
        "If an employee has 6 years of experience, we can predict the salary as\n",
        "\n",
        "y = 1(6) + 2 = 8\n",
        "\n",
        "So, the predicted salary is 8 lakhs.\n",
        "\n",
        "Key Assumptions of Simple Linear Regression\n",
        "\n",
        "There is a linear relationship between X and Y.\n",
        "\n",
        "The errors are independent.\n",
        "\n",
        "The variance of errors is constant (homoscedasticity).\n",
        "\n",
        "The errors are normally distributed.\n",
        "\n",
        "**Question** 2: What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "**Answer**: Simple Linear Regression is based on certain assumptions. If these assumptions are satisfied, the model gives accurate and reliable predictions.\n",
        "\n",
        "1. Linearity\n",
        "\n",
        "Meaning:\n",
        "There must be a straight-line relationship between the independent variable (X) and the dependent variable (Y). This means Y should increase or decrease at a constant rate as X changes.\n",
        "\n",
        "Example:\n",
        "Consider predicting salary based on years of experience.\n",
        "If salary increases by roughly the same amount each year, the relationship is linear and suitable for Simple Linear Regression.\n",
        "\n",
        "Years of Experience: 1, 2, 3, 4\n",
        "Salary (in lakhs): 3, 4, 5, 6\n",
        "\n",
        "This forms a straight-line pattern, so the linearity assumption is satisfied.\n",
        "\n",
        "If violated:\n",
        "If salary increases very slowly in early years and very fast later, the relationship becomes curved, and Simple Linear Regression will not work well.\n",
        "\n",
        "2. Independence of Errors\n",
        "\n",
        "Meaning:\n",
        "The errors (difference between actual and predicted values) should be independent. One error should not affect another.\n",
        "\n",
        "Example:\n",
        "While predicting daily sales, today’s error should not depend on yesterday’s error.\n",
        "If sales errors today are influenced by sales errors of the previous day, then errors are dependent.\n",
        "\n",
        "If violated:\n",
        "This usually happens in time-series data (like stock prices). In such cases, Simple Linear Regression is not suitable without modifications.\n",
        "\n",
        "3. Homoscedasticity\n",
        "\n",
        "Meaning:\n",
        "The variance of errors should be constant for all values of X. The spread of residuals should be roughly equal across the regression line.\n",
        "\n",
        "Example:\n",
        "Predicting house prices based on area:\n",
        "If prediction errors are small for both small and large houses, the assumption is satisfied.\n",
        "\n",
        "If violated:\n",
        "If small houses have small errors but large houses have very large errors, this is called heteroscedasticity, and it reduces the reliability of predictions.\n",
        "\n",
        "4. Normality of Errors\n",
        "\n",
        "Meaning:\n",
        "The errors (residuals) should follow a normal (bell-shaped) distribution with a mean of zero.\n",
        "\n",
        "Example:\n",
        "While predicting exam scores based on study hours, most prediction errors should be close to zero, with fewer large positive or negative errors.\n",
        "\n",
        "If violated:\n",
        "If errors are highly skewed, statistical tests and confidence intervals become unreliable.\n",
        "\n",
        "5. No Influence of Other Variables\n",
        "\n",
        "Meaning:\n",
        "The dependent variable should be mainly influenced by the single independent variable used in the model.\n",
        "\n",
        "Example:\n",
        "If we predict weight based on height, but diet and exercise heavily influence weight, the model may not perform well because important variables are missing.\n",
        "\n",
        "If violated:\n",
        "The model may give biased or misleading results due to omitted variables.\n",
        "\n",
        "**Question 3**: Write the mathematical equation for a simple linear regression model and\n",
        "explain each term.\n",
        "\n",
        "A**nswer**: The mathematical equation of a Simple Linear Regression model is:\n",
        "\n",
        "y = mx + c\n",
        "\n",
        "(or)\n",
        "\n",
        "y = β₀ + β₁x\n",
        "\n",
        "Explanation of Each Term\n",
        "\n",
        "y (Dependent Variable)\n",
        "This is the output or target variable that we want to predict or explain.\n",
        "Example: Salary, house price, exam score.\n",
        "\n",
        "x (Independent Variable)\n",
        "This is the input or predictor variable used to explain changes in y.\n",
        "Example: Years of experience, house area, study hours.\n",
        "\n",
        "m or β₁ (Slope / Regression Coefficient)\n",
        "The slope represents the rate of change of y with respect to x.\n",
        "It tells us how much y changes when x increases by one unit.\n",
        "\n",
        "If m is positive, y increases as x increases.\n",
        "\n",
        "If m is negative, y decreases as x increases.\n",
        "\n",
        "Example:\n",
        "If m = 2, then for every 1-unit increase in x, y increases by 2 units.\n",
        "\n",
        "c or β₀ (Intercept)\n",
        "The intercept is the value of y when x = 0.\n",
        "It shows where the regression line crosses the y-axis.\n",
        "\n",
        "Example:\n",
        "If c = 5, then when x = 0, y = 5.\n",
        "\n",
        "Error Term (ε) [optional but important]\n",
        "In practice, the full model is written as:\n",
        "y = β₀ + β₁x + ε\n",
        "\n",
        "The error term represents the difference between the actual value and the predicted value. It captures the effect of factors not included in the model.\n",
        "\n",
        "Example Equation\n",
        "\n",
        "Suppose we want to predict salary based on years of experience, and the regression equation is:\n",
        "\n",
        "y = 1.5x + 2\n",
        "\n",
        "Here:\n",
        "\n",
        "y = Salary (in lakhs)\n",
        "\n",
        "x = Years of experience\n",
        "\n",
        "1.5 = Salary increase per year\n",
        "\n",
        "2 = Base salary when experience is zero\n",
        "\n",
        "This equation can be used to predict salary for any given experience value.\n",
        "\n",
        "**Question 4**: Provide a real-world example where simple linear regression can be\n",
        "applied.\n",
        "\n",
        "**Answer**:  A common real-world example where Simple Linear Regression can be applied is predicting house prices based on house size.\n",
        "\n",
        "Example Explanation\n",
        "\n",
        "Independent variable (X): House size (in square feet)\n",
        "\n",
        "Dependent variable (Y): House price\n",
        "\n",
        "As the size of a house increases, its price usually increases in a fairly linear manner. By collecting past data of house sizes and their corresponding prices, we can fit a simple linear regression model.\n",
        "\n",
        "Example Model\n",
        "\n",
        "Suppose the regression equation obtained is:\n",
        "\n",
        "y = 0.05x + 10\n",
        "\n",
        "where:\n",
        "\n",
        "y = House price (in lakhs)\n",
        "\n",
        "x = House size (in square feet)\n",
        "\n",
        "0.05 = Increase in price per square foot\n",
        "\n",
        "10 = Base price when size is zero (land value or fixed cost)\n",
        "\n",
        "Usage\n",
        "\n",
        "If a house has a size of 1000 sq ft, the predicted price would be:\n",
        "\n",
        "y = 0.05(1000) + 10 = 60 lakhs\n",
        "\n",
        "Why Simple Linear Regression Fits This Case\n",
        "\n",
        "There is one main influencing factor (house size).\n",
        "\n",
        "The relationship between size and price is approximately linear.\n",
        "\n",
        "The model is easy to interpret and useful for quick predictions.\n",
        "\n",
        "\n",
        "**Question 5**: What is the method of least squares in linear regression?\n",
        "\n",
        "**Answer**:What is the Method of Least Squares?\n",
        "\n",
        "The method of least squares is a mathematical technique used in linear regression to find the best-fitting straight line for a given set of data points.\n",
        "\n",
        "The “best-fitting” line is the one for which the sum of the squares of the errors (residuals) is minimum.\n",
        "\n",
        "Error (residual) = Actual value − Predicted value\n",
        "\n",
        "The method squares these errors so that positive and negative errors do not cancel each other.\n",
        "\n",
        "Why Do We Square the Errors?\n",
        "\n",
        "Squaring removes negative signs.\n",
        "\n",
        "Larger errors are penalized more heavily.\n",
        "\n",
        "It makes the mathematics easier to optimize.\n",
        "\n",
        "Mathematical Formulation\n",
        "\n",
        "The simple linear regression model is:\n",
        "\n",
        "y = β₀ + β₁x\n",
        "\n",
        "For each data point, the error is:\n",
        "\n",
        "eᵢ = yᵢ − (β₀ + β₁xᵢ)\n",
        "\n",
        "The objective of least squares is to minimize:\n",
        "\n",
        "Σ (yᵢ − (β₀ + β₁xᵢ))²\n",
        "\n",
        "This sum is called the Sum of Squared Errors (SSE).\n",
        "\n",
        "How Least Squares Finds the Best Line\n",
        "\n",
        "The method calculates values of β₀ (intercept) and β₁ (slope) such that the SSE is minimum.\n",
        "This is done using partial derivatives (calculus) or built-in algorithms in libraries like sklearn.\n",
        "\n",
        "Proper Real-World Example\n",
        "\n",
        "Problem:\n",
        "Predict exam marks based on number of study hours.\n",
        "\n",
        "Study Hours (X)\tMarks (Y)\n",
        "1\t40\n",
        "2\t50\n",
        "3\t60\n",
        "4\t65\n",
        "5\t75\n",
        "Step 1: Fit a Regression Line\n",
        "\n",
        "Assume the regression equation obtained using least squares is:\n",
        "\n",
        "y = 8x + 32\n",
        "\n",
        "Step 2: Calculate Errors\n",
        "X\tActual Y\tPredicted Y (8x + 32)\tError (Y − Ŷ)\tSquared Error\n",
        "1\t40\t40\t0\t0\n",
        "2\t50\t48\t2\t4\n",
        "3\t60\t56\t4\t16\n",
        "4\t65\t64\t1\t1\n",
        "5\t75\t72\t3\t9\n",
        "\n",
        "Sum of Squared Errors (SSE) = 0 + 4 + 16 + 1 + 9 = 30\n",
        "\n",
        "Why This Line is the Best Fit\n",
        "\n",
        "If we try any other line, the sum of squared errors will be greater than 30.\n",
        "Therefore, the line y = 8x + 32 is considered the best-fit line according to the least squares method.\n",
        "\n",
        "Key Points to Remember\n",
        "\n",
        "Least squares minimizes the sum of squared residuals.\n",
        "\n",
        "It gives the most accurate straight-line fit for data.\n",
        "\n",
        "It is the foundation of linear regression models.\n",
        "\n",
        "Used extensively in statistics, machine learning, economics, and business analysis.\n",
        "\n",
        "**Question 6**: What is Logistic Regression? How does it differ from Linear Regression?\n",
        "\n",
        "**Answer**: What is Logistic Regression?\n",
        "\n",
        "Logistic Regression is a supervised machine learning algorithm used for classification problems, especially when the dependent variable is categorical (most commonly binary).\n",
        "\n",
        "Instead of predicting a continuous value, Logistic Regression predicts the probability that an observation belongs to a particular class using the logistic (sigmoid) function.\n",
        "\n",
        "The output probability lies between 0 and 1, and based on a threshold (usually 0.5), the model assigns a class label.\n",
        "\n",
        "Logistic Regression Model\n",
        "\n",
        "The logistic regression equation is:\n",
        "\n",
        "z = β₀ + β₁x\n",
        "\n",
        "Probability is calculated using the sigmoid function:\n",
        "\n",
        "p = 1 / (1 + e⁻ᶻ)\n",
        "\n",
        "where\n",
        "\n",
        "p = probability of the positive class\n",
        "\n",
        "z = linear combination of inputs\n",
        "\n",
        "Example of Logistic Regression\n",
        "\n",
        "Predicting whether an email is spam or not spam:\n",
        "\n",
        "Independent variable (X): Email features (e.g., number of links)\n",
        "\n",
        "Dependent variable (Y): Spam (1) or Not Spam (0)\n",
        "\n",
        "If the predicted probability is 0.8, the email is classified as spam.\n",
        "If it is 0.3, the email is classified as not spam.\n",
        "\n",
        "Difference Between Linear Regression and Logistic Regression\n",
        "Feature\tLinear Regression\tLogistic Regression\n",
        "Type of Problem\tRegression\tClassification\n",
        "Output\tContinuous values\tProbability (0 to 1)\n",
        "Dependent Variable\tContinuous\tCategorical (binary)\n",
        "Function Used\tLinear function\tSigmoid (logistic) function\n",
        "Range of Output\t−∞ to +∞\t0 to 1\n",
        "Cost Function\tMean Squared Error\tLog Loss (Cross-Entropy)\n",
        "Example Use Case\tPredict salary, house price\tSpam detection, disease prediction\n",
        "Key Differences Explained Simply\n",
        "\n",
        "Linear Regression predicts numerical values like price or salary.\n",
        "\n",
        "Logistic Regression predicts the probability of an event happening.\n",
        "\n",
        "Linear Regression fits a straight line, while Logistic Regression fits an S-shaped curve.\n",
        "\n",
        "Logistic Regression is more suitable when outcomes are yes/no or true/false.\n",
        "\n",
        "\n",
        "**Question 7:** Name and briefly describe three common evaluation metrics for regression\n",
        "models.\n",
        "\n",
        " **Answer:** Three common evaluation metrics used for regression models are:\n",
        "\n",
        "1. Mean Absolute Error (MAE)\n",
        "\n",
        "Description:\n",
        "MAE measures the average absolute difference between the actual values and the predicted values. It tells us, on average, how far the predictions are from the true values.\n",
        "\n",
        "Formula:\n",
        "MAE = (1/n) Σ |y − ŷ|\n",
        "\n",
        "Key Point:\n",
        "\n",
        "Easy to understand and interpret\n",
        "\n",
        "Treats all errors equally\n",
        "\n",
        "Example:\n",
        "If MAE = 2, it means the predictions are off by an average of 2 units.\n",
        "\n",
        "2. Mean Squared Error (MSE)\n",
        "\n",
        "Description:\n",
        "MSE calculates the average of the squared differences between actual and predicted values. Larger errors are penalized more heavily due to squaring.\n",
        "\n",
        "Formula:\n",
        "MSE = (1/n) Σ (y − ŷ)²\n",
        "\n",
        "Key Point:\n",
        "\n",
        "Sensitive to outliers\n",
        "\n",
        "Useful when large errors are particularly undesirable\n",
        "\n",
        "Example:\n",
        "If MSE = 10, it indicates higher penalty for large prediction errors.\n",
        "\n",
        "3. Root Mean Squared Error (RMSE)\n",
        "\n",
        "Description:\n",
        "RMSE is the square root of MSE, which brings the error metric back to the same unit as the target variable.\n",
        "\n",
        "Formula:\n",
        "RMSE = √MSE\n",
        "\n",
        "Key Point:\n",
        "\n",
        "Easier to interpret than MSE\n",
        "\n",
        "Strongly penalizes large errors\n",
        "\n",
        "Example:\n",
        "If RMSE = 3, predictions deviate from actual values by about 3 units on average.\n",
        "\n",
        "Question 8: What is the purpose of the R-squared metric in regression analysis?\n",
        "\n",
        "Answer:  The R-squared (R²) metric is used in regression analysis to measure how well the regression model explains the variation in the dependent variable.\n",
        "\n",
        "Purpose of R-squared\n",
        "\n",
        "The main purpose of R-squared is to show the goodness of fit of a regression model.\n",
        "It tells us how much of the total variation in the output variable is explained by the input variable(s).\n",
        "\n",
        "Meaning of R-squared Value\n",
        "\n",
        "R² values range from 0 to 1\n",
        "\n",
        "Sometimes expressed as a percentage\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "R² = 0 → The model explains none of the variability in the data\n",
        "\n",
        "R² = 1 → The model explains all the variability in the data\n",
        "\n",
        "Example\n",
        "\n",
        "Suppose we are predicting house prices based on house size.\n",
        "\n",
        "If R² = 0.85, it means:\n",
        "\n",
        "85% of the variation in house prices is explained by house size\n",
        "\n",
        "The remaining 15% is due to other factors (location, age of house, market conditions, etc.)\n",
        "\n",
        "Why R-squared is Important\n",
        "\n",
        "Helps compare different regression models\n",
        "\n",
        "Indicates how well the model fits the data\n",
        "\n",
        "Shows the explanatory power of independent variables\n",
        "\n",
        "Limitations of R-squared\n",
        "\n",
        "A high R² does not always mean the model is good\n",
        "\n",
        "It does not indicate whether predictions are accurate\n",
        "\n",
        "It always increases when more variables are added, even if they are irrelevant\n",
        "\n",
        "**Question 9**: Write Python code to fit a simple linear regression model using scikit-learn\n",
        "and print the slope and intercept.\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "**Answer**: Below is an example of Python code using scikit-learn to fit a Simple Linear Regression model and print the slope and intercept, along with the output.\n",
        "\n",
        "# Import required libraries\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Sample data (Independent variable and Dependent variable)\n",
        "# X must be 2D\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)   # Years of experience\n",
        "y = np.array([3, 4, 5, 6, 7])                  # Salary (in lakhs)\n",
        "\n",
        "# Create Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get slope and intercept\n",
        "slope = model.coef_[0]\n",
        "intercept = model.intercept_\n",
        "\n",
        "# Print results\n",
        "print(\"Slope:\", slope)\n",
        "print(\"Intercept:\", intercept)\n",
        "\n",
        "Slope: 1.0\n",
        "Intercept: 2.0\n",
        "\n",
        "Explanation:\n",
        "\n",
        "Slope (1.0): For every 1-unit increase in X, Y increases by 1 unit\n",
        "\n",
        "Intercept (2.0): When X = 0, the predicted value of Y is 2\n",
        "\n",
        "This confirms the regression equation:\n",
        "y = 1x + 2\n",
        "\n",
        "**Question 10**: How do you interpret the coefficients in a simple linear regression model?\n",
        "\n",
        "**Answer**: In a Simple Linear Regression model, the coefficients explain how the independent variable influences the dependent variable. The model is written as:\n",
        "\n",
        "y = β₀ + β₁x\n",
        "\n",
        "Interpretation of Each Coefficient\n",
        "1. Slope Coefficient (β₁)\n",
        "\n",
        "Meaning:\n",
        "The slope tells us how much the dependent variable (y) changes when the independent variable (x) increases by one unit, while keeping everything else constant.\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "If β₁ > 0 → y increases as x increases (positive relationship)\n",
        "\n",
        "If β₁ < 0 → y decreases as x increases (negative relationship)\n",
        "\n",
        "If β₁ = 0 → no relationship between x and y\n",
        "\n",
        "Example:\n",
        "If β₁ = 2, then for every 1-unit increase in x, y increases by 2 units.\n",
        "Example: For every extra year of experience, salary increases by 2 lakhs.\n",
        "\n",
        "2. Intercept Coefficient (β₀)\n",
        "\n",
        "Meaning:\n",
        "The intercept represents the value of the dependent variable when the independent variable x is zero.\n",
        "\n",
        "Interpretation:\n",
        "It shows the starting point of the regression line on the y-axis.\n",
        "\n",
        "Example:\n",
        "If β₀ = 5, then when x = 0, y = 5.\n",
        "Example: A person with zero years of experience has a base salary of 5 lakhs.\n",
        "\n",
        "Combined Interpretation with Example\n",
        "\n",
        "Suppose the regression equation is:\n",
        "\n",
        "y = 5 + 2x\n",
        "\n",
        "Where:\n",
        "\n",
        "x = Years of experience\n",
        "\n",
        "y = Salary (in lakhs)\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "Base salary is 5 lakhs when experience is zero\n",
        "\n",
        "Each additional year of experience increases salary by 2 lakhs\n",
        "\n",
        "Key Points to Remember\n",
        "\n",
        "Coefficients explain the direction, strength, and nature of the relationship\n",
        "\n",
        "Interpretation always depends on the units of x and y\n",
        "\n",
        "Coefficients help in understanding real-world impact, not just prediction"
      ],
      "metadata": {
        "id": "FSVBgN9KtvO6"
      }
    }
  ]
}