{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "18e9da5d",
      "metadata": {
        "id": "18e9da5d"
      },
      "source": [
        "### What is a parameter?\n",
        "\n",
        "A *parameter* is a variable in a model that is learned from data. For example, weights in a linear regression or neural network are parameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f5c5046",
      "metadata": {
        "id": "9f5c5046"
      },
      "source": [
        "### What is correlation?\n",
        "\n",
        "Correlation measures the linear relationship between two variables. Values range from -1 (perfect negative linear relationship) to +1 (perfect positive linear relationship).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2803d837",
      "metadata": {
        "id": "2803d837"
      },
      "source": [
        "### What does negative correlation mean?\n",
        "\n",
        "Negative correlation means that as one variable increases, the other tends to decrease. For example, temperature vs. heating energy use (in some contexts) might be negatively correlated.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c5c3fdb",
      "metadata": {
        "id": "0c5c3fdb"
      },
      "source": [
        "### Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "Machine Learning (ML) is a field of computer science that builds algorithms that learn patterns from data to make predictions or decisions. Main components:\n",
        "\n",
        "- **Data** (features and labels)\n",
        "- **Model** (hypothesis or algorithm)\n",
        "- **Loss function** (how we measure errors)\n",
        "- **Optimizer / Training procedure** (how we update parameters)\n",
        "- **Evaluation** (metrics, test set)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "548be432",
      "metadata": {
        "id": "548be432"
      },
      "source": [
        "### How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "The loss function quantifies how well the model's predictions match the true values on a dataset. Lower loss usually indicates better fit. But watch out for overfitting: very low training loss and high test loss indicates poor generalization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4a5245b",
      "metadata": {
        "id": "d4a5245b"
      },
      "source": [
        "### What are continuous and categorical variables?\n",
        "\n",
        "**Continuous** variables take numeric values on a continuum (e.g., height, temperature). **Categorical** variables take a finite set of discrete values (e.g., color: red/green/blue).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "275745ab",
      "metadata": {
        "id": "275745ab"
      },
      "source": [
        "### How do we handle categorical variables in Machine Learning? Common techniques?\n",
        "\n",
        "Common techniques:\n",
        "\n",
        "- **Label Encoding**: assign integer IDs to categories (suitable for ordinal categories).\n",
        "- **One-Hot Encoding**: create binary columns for each category (good for nominal categories).\n",
        "- **Target / Mean Encoding**: replace categories with the mean target value (use carefully to avoid leakage).\n",
        "- **Binary / Hashing encoding**: for high-cardinality features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3f29e3e",
      "metadata": {
        "id": "b3f29e3e"
      },
      "source": [
        "### What do you mean by training and testing a dataset?\n",
        "\n",
        "Training is the process of fitting a model's parameters using labeled data. Testing (evaluation) is measuring model performance on held-out data that the model did not see during training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28e92907",
      "metadata": {
        "id": "28e92907"
      },
      "source": [
        "### What is sklearn.preprocessing?\n",
        "\n",
        "A scikit-learn module that contains tools for feature scaling, encoding, normalization, imputation, and other preprocessing functionality (e.g., StandardScaler, MinMaxScaler, OneHotEncoder).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "221604ad",
      "metadata": {
        "id": "221604ad"
      },
      "source": [
        "### What is a Test set?\n",
        "\n",
        "A test set is a portion of data held out from training and used only to evaluate final model performance and estimate generalization error.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae231f4d",
      "metadata": {
        "id": "ae231f4d"
      },
      "source": [
        "### How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "Typically we use `train_test_split` from `sklearn.model_selection` to split arrays or DataFrames into training and test sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bb1133f",
      "metadata": {
        "id": "9bb1133f"
      },
      "source": [
        "### How do you approach a Machine Learning problem?\n",
        "\n",
        "Short approach:\n",
        "1. Understand problem & success metric\n",
        "2. Collect & inspect data (EDA)\n",
        "3. Clean & preprocess\n",
        "4. Feature engineering\n",
        "5. Choose baseline model\n",
        "6. Train & validate (cross-validation)\n",
        "7. Tune hyperparameters\n",
        "8. Evaluate on test set\n",
        "9. Deploy & monitor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b549c64b",
      "metadata": {
        "id": "b549c64b"
      },
      "source": [
        "### Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "Exploratory Data Analysis (EDA) helps detect data issues (missing values, outliers), understand feature distributions and relationships (correlations), and design appropriate preprocessing and modeling strategies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7d02f31",
      "metadata": {
        "id": "d7d02f31"
      },
      "source": [
        "### How can you find correlation between variables in Python?\n",
        "\n",
        "Use `pandas.DataFrame.corr()` for Pearson correlation, `scipy.stats` for other correlation measures (Spearman, Kendall).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ee19ac7",
      "metadata": {
        "id": "0ee19ac7"
      },
      "source": [
        "### What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "Causation means one event causes another. Correlation is only association. Example: ice cream sales and drowning incidents are correlated (both increase in summer) but ice cream does not cause drowning. Temperature (a confounder) causes both to rise.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea8f533c",
      "metadata": {
        "id": "ea8f533c"
      },
      "source": [
        "### What is an Optimizer? Types and examples.\n",
        "\n",
        "An optimizer updates model parameters to minimize the loss. Examples:\n",
        "\n",
        "- **Gradient Descent (GD)**: full-batch updates using gradient of loss over entire dataset.\n",
        "- **Stochastic Gradient Descent (SGD)**: uses one example (or mini-batch) per update.\n",
        "- **Momentum**: accelerates SGD by adding a fraction of previous update.\n",
        "- **Adam**: adaptive moment estimates combining momentum and per-parameter adaptive learning rates.\n",
        "\n",
        "Each has trade-offs: SGD noisy but scalable; Adam often converges faster in deep learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2865b9cb",
      "metadata": {
        "id": "2865b9cb"
      },
      "source": [
        "### What is sklearn.linear_model?\n",
        "\n",
        "A scikit-learn module with linear models (LinearRegression, LogisticRegression, Ridge, Lasso, SGDClassifier, etc.).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb5076f7",
      "metadata": {
        "id": "cb5076f7"
      },
      "source": [
        "### What does model.fit() do? What arguments must be given?\n",
        "\n",
        "`model.fit(X, y)` trains the model on features `X` and labels `y`. Some models accept sample weights or additional args; consult the estimator docs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bc700e2",
      "metadata": {
        "id": "8bc700e2"
      },
      "source": [
        "### What does model.predict() do? What arguments must be given?\n",
        "\n",
        "`model.predict(X_new)` returns predictions for new features `X_new`. For probabilistic outputs, use `model.predict_proba(X_new)` (if supported).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4baa3774",
      "metadata": {
        "id": "4baa3774"
      },
      "source": [
        "### What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "Feature scaling rescales numeric features to a comparable range (e.g., zero mean unit variance). It helps models that use distance (KNN, SVM) or gradient-based optimization converge faster.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfda55f6",
      "metadata": {
        "id": "cfda55f6"
      },
      "source": [
        "### How do we perform scaling in Python?\n",
        "\n",
        "Use `StandardScaler`, `MinMaxScaler`, or `RobustScaler` from `sklearn.preprocessing`. Fit the scaler on training data and transform both train and test using the same scaler.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c390132d",
      "metadata": {
        "id": "c390132d"
      },
      "source": [
        "### Explain data encoding?\n",
        "\n",
        "Data encoding transforms categorical/text features into numeric form suitable for ML models (label encoding, one-hot encoding, target encoding, embeddings).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "697f4b71",
      "metadata": {
        "id": "697f4b71"
      },
      "source": [
        "## Hands-on demo: Iris + synthetic regression dataset\n",
        "We'll demonstrate EDA, correlation, encoding, scaling, train/test split, model training and evaluation, and charts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5077f92f",
      "metadata": {
        "id": "5077f92f"
      },
      "outputs": [],
      "source": [
        "# Standard imports and dataset loading\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, log_loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# load iris dataset (classification demo)\n",
        "iris = datasets.load_iris()\n",
        "X_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y_iris = pd.Series(iris.target, name='species')\n",
        "df_iris = pd.concat([X_iris, y_iris], axis=1)\n",
        "df_iris.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8af30cef",
      "metadata": {
        "id": "8af30cef"
      },
      "outputs": [],
      "source": [
        "# Basic EDA: distributions & scatter plots\n",
        "# 1) Histograms for numeric features\n",
        "for col in X_iris.columns:\n",
        "    plt.figure()\n",
        "    plt.hist(X_iris[col])\n",
        "    plt.title(f'Histogram of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('count')\n",
        "    plt.show()\n",
        "\n",
        "# 2) Scatter plot: sepal length vs sepal width\n",
        "plt.figure()\n",
        "plt.scatter(X_iris['sepal length (cm)'], X_iris['sepal width (cm)'])\n",
        "plt.xlabel('sepal length (cm)')\n",
        "plt.ylabel('sepal width (cm)')\n",
        "plt.title('Sepal length vs Sepal width (scatter)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75af0880",
      "metadata": {
        "id": "75af0880"
      },
      "outputs": [],
      "source": [
        "# Correlation matrix and simple heatmap (Pearson)\n",
        "corr = df_iris.corr()\n",
        "corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ebb9ea2",
      "metadata": {
        "id": "2ebb9ea2"
      },
      "outputs": [],
      "source": [
        "# Visualize correlation matrix with imshow\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.imshow(corr, interpolation='nearest')\n",
        "plt.xticks(range(len(corr)), corr.columns, rotation=45)\n",
        "plt.yticks(range(len(corr)), corr.columns)\n",
        "plt.colorbar()\n",
        "plt.title('Correlation matrix (imshow)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a9d2abd",
      "metadata": {
        "id": "5a9d2abd"
      },
      "source": [
        "### Encoding categorical feature example\n",
        "We'll create a small categorical column and show Label Encoding vs One-Hot Encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2196a81",
      "metadata": {
        "id": "c2196a81"
      },
      "outputs": [],
      "source": [
        "# Create a small categorical column\n",
        "df_demo = pd.DataFrame({\n",
        "    'num': [1.2, 3.4, 2.2, 5.1],\n",
        "    'color': ['red', 'blue', 'green', 'red']\n",
        "})\n",
        "df_demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f270db6",
      "metadata": {
        "id": "4f270db6"
      },
      "outputs": [],
      "source": [
        "# One-Hot Encoding using pandas.get_dummies and sklearn.OneHotEncoder\n",
        "ohe_pd = pd.get_dummies(df_demo['color'], prefix='color')\n",
        "ohe_pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59a83043",
      "metadata": {
        "id": "59a83043"
      },
      "outputs": [],
      "source": [
        "encoder = OneHotEncoder(sparse=False, drop=None)\n",
        "enc = encoder.fit_transform(df_demo[['color']])\n",
        "enc_df = pd.DataFrame(enc, columns=encoder.get_feature_names_out(['color']))\n",
        "enc_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ed2c61e",
      "metadata": {
        "id": "4ed2c61e"
      },
      "source": [
        "### Scaling example (StandardScaler)\n",
        "Fit scaler on training split and transform both train and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d2cbaab",
      "metadata": {
        "id": "9d2cbaab"
      },
      "outputs": [],
      "source": [
        "# Create a regression dataset for scaling and modeling demo\n",
        "from sklearn.datasets import make_regression\n",
        "X_reg, y_reg = make_regression(n_samples=200, n_features=3, noise=10, random_state=42)\n",
        "df_reg = pd.DataFrame(X_reg, columns=['f1', 'f2', 'f3'])\n",
        "df_reg['target'] = y_reg\n",
        "df_reg.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1a9c4e2",
      "metadata": {
        "id": "c1a9c4e2"
      },
      "outputs": [],
      "source": [
        "# Train/test split\n",
        "X = df_reg[['f1','f2','f3']]\n",
        "y = df_reg['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Fit a linear regression model and evaluate MSE\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "y_pred = lr.predict(X_test_scaled)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print('Test MSE (LinearRegression with StandardScaler):', mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd576512",
      "metadata": {
        "id": "dd576512"
      },
      "source": [
        "### Demonstration of training and prediction with classification (Iris)\n",
        "We'll train a LogisticRegression and show `fit()` and `predict()` usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b607326",
      "metadata": {
        "id": "0b607326"
      },
      "outputs": [],
      "source": [
        "# Prepare iris for classification demo\n",
        "X = X_iris\n",
        "y = y_iris\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# Feature scaling for LogisticRegression (optional but often helpful)\n",
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_test_s = scaler.transform(X_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=200)\n",
        "clf.fit(X_train_s, y_train)  # model.fit(X, y)\n",
        "y_pred = clf.predict(X_test_s)  # model.predict(X_new)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print('Iris test accuracy:', acc)\n",
        "\n",
        "# If model supports predict_proba we can inspect probabilities and compute log-loss (a loss function)\n",
        "if hasattr(clf, 'predict_proba'):\n",
        "    probs = clf.predict_proba(X_test_s)\n",
        "    ll = log_loss(y_test, probs)\n",
        "    print('Log loss on test set:', ll)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c13e5375",
      "metadata": {
        "id": "c13e5375"
      },
      "source": [
        "## Short note on Loss and Overfitting\n",
        "- The **loss** quantifies model error (e.g., MSE for regression, log-loss for probabilistic classification).\n",
        "- Track training vs validation loss: if training loss is much lower than validation loss, model overfits."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "082a436b",
      "metadata": {
        "id": "082a436b"
      },
      "source": [
        "## Full-Stack Web Development â€” Compact guide + minimal example\n",
        "This section contains a short overview and a small Flask app (server) + simple frontend (HTML/JS). The Flask app below serves a single page and a JSON API. In Colab you cannot run a long-lived server for external traffic, but the code is runnable locally or in an environment that allows incoming connections.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69f2ca61",
      "metadata": {
        "id": "69f2ca61"
      },
      "outputs": [],
      "source": [
        "# Flask app example (save as app.py locally and run: `python app.py`)\n",
        "flask_example = \"\"\"from flask import Flask, jsonify, render_template_string, request\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "INDEX_HTML = '''\n",
        "<!doctype html>\n",
        "<html>\n",
        "  <head>\n",
        "    <meta charset=\"utf-8\"/>\n",
        "    <title>Mini Flask + Frontend</title>\n",
        "  </head>\n",
        "  <body>\n",
        "    <h1>Mini Full-Stack Example</h1>\n",
        "    <div id=\"message\">Press the button to call the API.</div>\n",
        "    <button onclick=\"callApi()\">Call API</button>\n",
        "    <script>\n",
        "      async function callApi() {\n",
        "        const res = await fetch('/api/hello');\n",
        "        const data = await res.json();\n",
        "        document.getElementById('message').innerText = 'API says: ' + data.greeting;\n",
        "      }\n",
        "    </script>\n",
        "  </body>\n",
        "</html>\n",
        "'''\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template_string(INDEX_HTML)\n",
        "\n",
        "@app.route('/api/hello')\n",
        "def api_hello():\n",
        "    return jsonify({'greeting': 'Hello from Flask!'})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True, port=5000)\n",
        "\"\"\"\n",
        "print('Flask snippet created. Save to app.py and run locally to test.')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}